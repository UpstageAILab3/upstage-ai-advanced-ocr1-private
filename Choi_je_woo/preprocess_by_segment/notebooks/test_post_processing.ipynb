{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영수증 추출한 test이미지의 후처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_with_red_mask(result_dict, image, image_name):\n",
    "    # 결과를 area 기준으로 정렬\n",
    "    sorted_results = sorted(result_dict, key=lambda x: x['area'], reverse=True)\n",
    "    \n",
    "    # 가장 큰 segment 가져오기\n",
    "    largest_segment = sorted_results[0]\n",
    "    \n",
    "    # segmentation mask 가져오기\n",
    "    segmentation_mask = largest_segment['segmentation']\n",
    "    \n",
    "    # 원본 이미지 복사\n",
    "    overlay_image = image.copy()\n",
    "    \n",
    "    # 붉은색 투명 마스크 적용\n",
    "    red_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    red_mask[segmentation_mask] = [0, 0, 255]  # 붉은색 (BGR 포맷)\n",
    "    \n",
    "    # 투명도 적용 (0.5 투명한 마스크)\n",
    "    alpha = 0.5\n",
    "    overlay_image = cv2.addWeighted(red_mask, alpha, overlay_image, 1 - alpha, 0)\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))  # OpenCV는 BGR이므로 RGB로 변환\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Largest Segment {image_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_largest_segment_without_mask(result_dict, image, output_path, image_name):\n",
    "    # 결과를 area 기준으로 정렬\n",
    "    sorted_results = sorted(result_dict, key=lambda x: x['area'], reverse=True)\n",
    "    \n",
    "    # 가장 큰 segment 가져오기\n",
    "    largest_segment = sorted_results[0]\n",
    "    \n",
    "    # segmentation mask 가져오기\n",
    "    segmentation_mask = largest_segment['segmentation']\n",
    "    \n",
    "    # 마스크 적용하여 해당 부분만 추출\n",
    "    mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "    mask[segmentation_mask] = 1  # 마스크 부분을 1로 설정\n",
    "    \n",
    "    # 이미지에 마스크 적용해서 해당 부분만 추출\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Bounding box를 사용해 해당 영역만 crop\n",
    "    x, y, w, h = largest_segment['bbox']\n",
    "    x , y, w, h = int(x), int(y), int(w), int(h)\n",
    "    cropped_segment = segmented_image[y:y+h, x:x+w]\n",
    "\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    # plt.imshow(cv2.cvtColor(cropped_segment, cv2.COLOR_BGR2RGB))  # OpenCV는 BGR이므로 RGB로 변환\n",
    "    # plt.axis('off')\n",
    "    # plt.title(f\"Largest Segment {image_name}\")\n",
    "    # plt.show()\n",
    "\n",
    "    # 결과 저장\n",
    "    cv2.imwrite(output_path+image_name, cropped_segment)\n",
    "    # print(f\"Segmented image saved to {output_path+image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_data(original_data, adjusted_data, image_name, result_dict, idx):\n",
    "    # 원본 이미지에서 자른 영역의 좌상단 좌표 (x, y)\n",
    "    sorted_results = sorted(result_dict, key=lambda x: x['area'], reverse=True)\n",
    "    largest_segment = sorted_results[idx]\n",
    "\n",
    "    cropped_x, cropped_y, _, _ = largest_segment['bbox']  # 자른 이미지의 좌표 값\n",
    "    cropped_x = int(cropped_x)\n",
    "    cropped_y = int(cropped_y)\n",
    "\n",
    "    # 좌표 조정\n",
    "    \n",
    "    image_data = original_data['images'][image_name]\n",
    "    adjusted_words = {}\n",
    "    for word_id, word_info in image_data['words'].items():\n",
    "        points = word_info['points']\n",
    "        \n",
    "        # 모든 좌표에서 자른 좌표의 (x, y)를 빼줌\n",
    "        adjusted_points = [\n",
    "            [point[0] + cropped_x, point[1] + cropped_y] for point in points\n",
    "        ]\n",
    "        \n",
    "        # 조정된 points를 저장\n",
    "        adjusted_words[word_id] = {\n",
    "            'points': adjusted_points,\n",
    "            # 'orientation': word_info['orientation'],\n",
    "            # 'language': word_info['language']\n",
    "        }\n",
    "        \n",
    "    #     adjusted_data['images'][image_name] = {'words': adjusted_words}\n",
    "    # return adjusted_data\n",
    "    return {'words': adjusted_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic mask generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run automatic mask generation, provide a SAM model to the `SamAutomaticMaskGenerator` class. Set the path below to the SAM checkpoint. Running on CUDA and with the default model is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test json의 후처리 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 파일 경로와 이미지 경로 설정\n",
    "\n",
    "# json_path = '/root/outputs/resnet50_type07_newimg/submissions/20241018_184749_new_test.json'\n",
    "json_path = '/root/outputs/efficientnet_b0/submissions/20241024_014437.json'\n",
    "image_base_path = '/root/data/datasets/images/test/'\n",
    "output_path = '/root/data/datasets/remove_background/test/'\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [16:15<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# 수정한 json파일\n",
    "adjusted_data = {'images': {}}\n",
    "\n",
    "# for image_json, i in zip(data['images'].items(), range(5)):\n",
    "for image_json in tqdm(test_data['images'].items()):\n",
    "    # 임시 횟수 제한\n",
    "    # if i == 5:\n",
    "    #     break\n",
    "    image_name, image_data = image_json\n",
    "\n",
    "    image = cv2.imread(image_base_path+image_name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "    # 수정한 json을 저장\n",
    "    # result_json = adjust_data(val_data, adjusted_data, image_name, masks)\n",
    "    adjusted_data['images'][image_name] = adjust_data(test_data, adjusted_data, image_name, masks, 0)\n",
    "\n",
    "    # visualize_with_red_mask(masks, image, image_name)\n",
    "    # save_largest_segment_without_mask(masks, image, output_path, image_name)\n",
    "# 조정된 JSON 파일 저장\n",
    "# with open('/root/data/datasets/jsons/adjusted_val.json', 'w') as f:\n",
    "#     json.dump(adjusted_data, f, indent=4)\n",
    "\n",
    "with open('/root/outputs/efficientnet_b0/submissions/20241024_014437_post_pro.json', 'w') as f:\n",
    "    json.dump(adjusted_data, f, indent=4)\n",
    "# with open('./adjusted_val1.json', 'w') as f:\n",
    "#     json.dump(result_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/root/outputs/efficientnet_b0/submissions/20241024_014437_post_pro.json'\n",
    "# image_base_path = '/root/data/datasets/images/test/'\n",
    "# output_path = '/root/data/datasets/remove_background/test/'\n",
    "\n",
    "# 1차 조정 JSON 파일 로드\n",
    "# with open(json_path, 'r', encoding='utf-8') as f:\n",
    "#     adjusted_data = json.load(f)\n",
    "\n",
    "json_path = '/root/outputs/efficientnet_b0/submissions/20241024_014437.json'\n",
    "\n",
    "# 무조정 JSON 파일 로드\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "\n",
    "json_path = '/root/data/datasets/jsons/need_more_segment_background.json'\n",
    "\n",
    "# 이상 데이터 json목록 로드\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    list_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:35<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "for image_name in tqdm(list_data['test']):\n",
    "    image_data = test_data['images'][image_name]\n",
    "\n",
    "    image = cv2.imread(image_base_path+image_name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "    # 수정한 json을 저장\n",
    "    # result_json = adjust_data(val_data, adjusted_data, image_name, masks)\n",
    "    adjusted_data['images'][image_name] = adjust_data(test_data, adjusted_data, image_name, masks, 1)\n",
    "\n",
    "with open('/root/outputs/efficientnet_b0/submissions/20241024_014437_post_pro.json', 'w') as f:\n",
    "    json.dump(adjusted_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/root/outputs/resnet50_type07_newimg/submissions/20241018_184749_new_test_post_pro2.json'\n",
    "image_base_path = '/root/data/datasets/images/test/'\n",
    "output_path = '/root/data/datasets/remove_background/test/'\n",
    "\n",
    "# 1차 조정 JSON 파일 로드\n",
    "# with open(json_path, 'r', encoding='utf-8') as f:\n",
    "#     adjusted_data = json.load(f)\n",
    "\n",
    "json_path = '/root/outputs/efficientnet_b0/submissions/20241024_014437.json'\n",
    "\n",
    "# 무조정 JSON 파일 로드\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "\n",
    "json_path = '/root/data/datasets/jsons/need_more_segment_background2.json'\n",
    "\n",
    "# 이상 데이터 json목록 로드\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    list_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for image_name in tqdm(list_data['test']):\n",
    "    image_data = test_data['images'][image_name]\n",
    "\n",
    "    image = cv2.imread(image_base_path+image_name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "    # 수정한 json을 저장\n",
    "    # result_json = adjust_data(val_data, adjusted_data, image_name, masks)\n",
    "    adjusted_data['images'][image_name] = adjust_data(test_data, adjusted_data, image_name, masks, 2)\n",
    "\n",
    "with open('/root/outputs/efficientnet_b0/submissions/20241024_014437_post_pro.json', 'w') as f:\n",
    "    json.dump(adjusted_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
